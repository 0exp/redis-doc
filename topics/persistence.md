Persistence
===

<a name="snapshotting"></a>
Snapshotting
---

By default Redis saves snapshots of the dataset on disk, in a binary
file called `dump.rdb`. You can configure Redis to have it save the
dataset every N seconds if there are at least M changes in the dataset,
or you can manually call the `SAVE` or `BGSAVE` commands.

For example, this configuration will make Redis automatically dump the
dataset to disk every 60 seconds if at least 1000 keys changed:

    save 60 1000

This strategy is known as _snapshotting_.

### How it works

Whenever Redis needs to dump the dataset to disk, this is what happens:

* Redis [forks](http://linux.die.net/man/2/fork). We now have a child
and a parent process.

* The child starts to write the dataset to a temporary RDB file.

* When the child is done writing the new RDB file, it replaces the old
one.

This method allows Redis to benefit from copy-on-write semantics.

<a name="append-only-file"></a>
Append-only file
---

Snapshotting is not very durable. If your computer running Redis stops,
your power line fails, or you accidentally `kill -9` your instance, the
latest data written on Redis will get lost.  While this may not be a big
deal for some applications, there are use cases for full durability, and
in these cases Redis was not a viable option.

The _append-only file_ is an alternative, fully-durable strategy for
Redis.  It became available in version 1.1.

You can turn on the AOF in your configuration file:

    appendonly yes

From now on, every time Redis receives a command that changes the
dataset (e.g. `SET`) it will append it to the AOF.  When you restart
Redis it will re-play the AOF to rebuild the state.

### Log rewriting

As you can guess, the AOF gets bigger and bigger as write operations are
performed.  For example, if you are incrementing a counter 100 times,
you'll end up with a single key in your dataset containing the final
value, but 100 entries in your AOF. 99 of those entries are not needed
to rebuild the current state.

So Redis supports an interesting feature: it is able to rebuild the AOF
in the background without interrupting service to clients. Whenever
you issue a `BGREWRITEAOF` Redis will write the shortest sequence of
commands needed to rebuild the current dataset in memory.  If you're
using the AOF, you'll need to run `BGREWRITEAOF` from time to time.

### How durable is the append only file?

You can configure how many times Redis will
[`fsync`](http://linux.die.net/man/2/fsync) data on disk. There are
three options:

* `fsync` every time a new command is appended to the AOF. Very very
slow, very safe.

* `fsync` every second. Fast enough, and you can lose 1 second of data
if there is a disaster.

* Never `fsync`, just put your data in the hands of the Operating
System. The faster and less safe method.

The suggested (and default) policy is to `fsync` every second. It is
both very fast and pretty safe. The `always` policy is very slow in
practice (although it was improved in Redis 2.0) â€“ there is no way to
make `fsync` faster than it is.

### What should I do if my AOF gets corrupted?

It is possible that the server crashes while writing the AOF file (this
still should never lead to inconsistencies), corrupting the file in a
way that is no longer loadable by Redis. When this happens you can fix
this problem using the following procedure:

* Make a backup copy of your AOF file.

* Fix the original file using the `redis-check-aof` tool that ships with
Redis:

      $ redis-check-aof --fix <filename>
    
* Optionally use `diff -u` to check what is the difference between two
files.

* Restart the server with the fixed file.

### How it works

Log rewriting uses the same copy-on-write trick already in use for
snapshotting.  This is how it works:

* Redis [forks](http://linux.die.net/man/2/fork), so now we have a child
and a parent process.

* The child starts writing the new AOF in a temporary file.

* The parent accumulates all the new changes in an in-memory buffer (but
at the same time it writes the new changes in the old append-only file,
so if the rewriting fails, we are safe).

* When the child is done rewriting the file, the parent gets a signal,
and appends the in-memory buffer at the end of the file generated by the
child.

* Profit! Now Redis atomically renames the old file into the new one,
and starts appending new data into the new file.
